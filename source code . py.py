# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OCXWl6lbGUaIulY8e-0vQaOQHRilZdyD
"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Sample data (replace with your dataset)
data = {
    'text': [
        'Scientists confirm climate change is real',
        'The moon is made of green cheese says expert',
        'New study shows exercise improves health',
        'Aliens visited Earth last week claims insider',
        'COVID-19 vaccines are safe and effective',
        '5G towers spread coronavirus according to docs'
    ],
    'label': [0, 1, 0, 1, 0, 1]  # 0=real, 1=fake
}

df = pd.DataFrame(data)

# Feature extraction
tfidf = TfidfVectorizer(max_features=1000)
X = tfidf.fit_transform(df['text'])
y = df['label']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train model
model = MultinomialNB()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")

# Confusion matrix plot
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Real', 'Fake'],
            yticklabels=['Real', 'Fake'])
plt.title('Fake News Detection Performance')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.tight_layout()
plt.savefig('fake_news_detection.png')
plt.show()

# Test with new sample
sample_news = ["Vaccines contain microchips to track people"]
sample_vec = tfidf.transform(sample_news)
prediction = model.predict(sample_vec)
print("\nSample Prediction:")
print(f"Text: '{sample_news[0]}'")
print("Prediction:", "Fake" if prediction[0] == 1 else "Real")



"""# New section"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Sample data (replace with your dataset)
data = {
    'text': [
        'Scientists confirm climate change is real',
        'The moon is made of green cheese says expert',
        'New study shows exercise improves health',
        'Aliens visited Earth last week claims insider',
        'COVID-19 vaccines are safe and effective',
        '5G towers spread coronavirus according to docs'
    ],
    'label': [0, 1, 0, 1, 0, 1]  # 0=real, 1=fake
}

df = pd.DataFrame(data)

# Feature extraction
tfidf = TfidfVectorizer(max_features=1000)
X = tfidf.fit_transform(df['text'])
y = df['label']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train model
model = MultinomialNB()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")

# Confusion matrix plot
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Real', 'Fake'],
            yticklabels=['Real', 'Fake'])
plt.title('Fake News Detection Performance')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.tight_layout()
plt.savefig('fake_news_detection.png')
plt.show()

# Test with new sample
sample_news = ["Vaccines contain microchips to track people"]
sample_vec = tfidf.transform(sample_news)
prediction = model.predict(sample_vec)
print("\nSample Prediction:")
print(f"Text: '{sample_news[0]}'")
print("Prediction:", "Fake" if prediction[0] == 1 else "Real")